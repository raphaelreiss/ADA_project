{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "from requests import get\n",
    "from bs4 import BeautifulSoup\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "from IPython.core.display import SVG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "DUNNHUMBY_PATH = '../data/dunnhumby - The Complete Journey CSV/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/jerome/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords \n",
    "STOP_WORDS = list(set(stopwords.words('english')))\n",
    "STOP_WORDS.append('NFS')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manual addition of words that we want to ignore to the Stopwords list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_delete = [\"added\",\"ns\",\"made\",\"eaten\",\"type\",\"all\",\"as\",\"to\",\"of\"]\n",
    "STOP_WORDS.append(to_delete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(str1): \n",
    "    \"\"\"\n",
    "    parses the string in a list of string (words) with all type of separators thanks to regexes\n",
    "    \"\"\"\n",
    "    #matches any separator and any whitespace and transforms to mathc to lower case\n",
    "    temp = list(filter(None,re.split(\"[\\s;&@\\/:,\\*\\.\\(\\)\\{\\}\\\\-%\\\"\\'0-9]\",str1)))\n",
    "    #remove duplicate word, as there are many\n",
    "    temp = list(dict.fromkeys(temp))\n",
    "    temp = [i.lower() for i in temp if not i in STOP_WORDS]\n",
    "    temp = [to_transform[i] if i in to_transform else i for i in temp]\n",
    "    \n",
    "    return temp\n",
    "\n",
    "def trim_nutrient_name(str1):\n",
    "    \"\"\"\n",
    "    simplifies the names of the nutrients for easier access afterwards\n",
    "    \"\"\"\n",
    "    #matches any separator and any whitespace and transforms to match to lower case\n",
    "    temp = temp.lower()\n",
    "    temp = list(filter(None,re.split(\"[;&@\\/:,\\*\\.\\(\\)\\{\\}\\\\%\\\"\\']\",str1)))\n",
    "    #remove duplicate word, as there are many\n",
    "    temp = [i for i in temp if not i in STOP_WORDS]\n",
    "    if(temp[0] == \"fatty acids\"):\n",
    "        return str.strip(temp[0] + temp[1])\n",
    "    else:\n",
    "        return str.strip(temp[0])\n",
    "\n",
    "def get_amount(to_convert):\n",
    "    \"\"\"Returns the amount of a nutrient by taking into account the specified unit\n",
    "    \"\"\"\n",
    "    if(to_convert.unit_name == \"UG\"):\n",
    "        return to_convert.amount * 1e-6\n",
    "    elif(to_convert.unit_name == \"MG\"):\n",
    "        return to_convert.amount * 1e-3\n",
    "    else:\n",
    "        return to_convert.amount\n",
    "    \n",
    "def normalize_text(str1):\n",
    "    \"\"\"\n",
    "    simplifies the names of the foods for easier access afterwards\n",
    "    \"\"\"\n",
    "    #matches any separator and any whitespace and transforms to mathc to lower case\n",
    "    temp = re.sub(\"[;&@\\/:,\\*\\.\\(\\)\\{\\}\\\\%\\\"\\']\", ' ', str1)\n",
    "    temp = temp.lower()\n",
    "    words = temp.split()\n",
    "    words = [i for i in words if not i in STOP_WORDS]\n",
    "    temp = \" \".join(sorted(set(words), key=words.index))\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "products_df =  pd.read_csv(os.path.join(DUNNHUMBY_PATH,\"product.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRODUCT_ID</th>\n",
       "      <th>CURR_SIZE_OF_PRODUCT</th>\n",
       "      <th>ingredients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>25671</td>\n",
       "      <td>22 LB</td>\n",
       "      <td>[frozen, ice, crushed, cubed]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>26093</td>\n",
       "      <td></td>\n",
       "      <td>[bread, italian, french]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>26190</td>\n",
       "      <td>50 OZ</td>\n",
       "      <td>[fruit, shelf, stable, apple, sauce]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PRODUCT_ID CURR_SIZE_OF_PRODUCT                           ingredients\n",
       "0       25671                22 LB         [frozen, ice, crushed, cubed]\n",
       "2       26093                                   [bread, italian, french]\n",
       "3       26190                50 OZ  [fruit, shelf, stable, apple, sauce]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Product Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_We only take the categories which are food related, sorted manually the different departments_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "products_sorted = products_df.groupby('DEPARTMENT').count().sort_values(by = 'PRODUCT_ID',ascending = False)\n",
    "#NB: there are a few food in MISC. TRANS\n",
    "food_related = np.array(['NUTRITION','GROCERY','PASTRY','MEAT-PCKGD','SEAFOOD-PCKGD','PRODUCE','DELI','MEAT','SALAD BAR','GRO BAKERY','FROZEN GROCERY','SPIRITS','RESTAURANT',''])\n",
    "\n",
    "products_df = products_df[products_df.DEPARTMENT.isin(food_related)]\n",
    "\n",
    "#we put all the description in a ingredients column\n",
    "products_df['ingredients'] = products_df.COMMODITY_DESC + \" \" + products_df.SUB_COMMODITY_DESC\n",
    "products_df.drop([\"MANUFACTURER\",\"DEPARTMENT\",\"BRAND\",\"COMMODITY_DESC\",\"SUB_COMMODITY_DESC\"],axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We see words in the product dataset, we would like to write them out completely for clarity\n",
    "#TO ADD: SNKSCKYS/CRKR/CNDY\n",
    "to_transform = dict({\"frzn\":\"frozen\",\"refrgratd\":\"refrigerated\",\"brkfst\":\"breakfast\",\"whlsm\":\"wholesome\",\\\n",
    "                     \"crkr\":\"cracker\",\"cndy\":\"candy\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "products_df.ingredients = products_df.ingredients.apply(parse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           [frozen, ice, crushed, cubed]\n",
       "2                [bread, italian, french]\n",
       "3    [fruit, shelf, stable, apple, sauce]\n",
       "4             [cookies, cones, specialty]\n",
       "5          [spices, extracts, seasonings]\n",
       "Name: ingredients, dtype: object"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products_df.ingredients.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that we now have an easily parseable format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloaded food nutrients data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jerome/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3058: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "/Users/jerome/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3058: DtypeWarning: Columns (9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "dfList = {}\n",
    "for r, d, f in os.walk('../data/health'):\n",
    "    for file in f:\n",
    "        if '.csv' in file:\n",
    "            #print(file)\n",
    "            dfList[file] = pd.read_csv(os.path.join(r, file))\n",
    "            \n",
    "branded_food_df = dfList['branded_food.csv']\n",
    "\n",
    "#link the nutrient id with its name\n",
    "nutrient_df = dfList['nutrient.csv']\n",
    "\n",
    "#contains the food articles name and their id test commit\n",
    "food_df = dfList['food.csv']\n",
    "\n",
    "#contains the nutrients for each food article\n",
    "food_nutrients_df = dfList['food_nutrient.csv']\n",
    "\n",
    "# linke the food articles ids to their potential category\n",
    "food_category_df = dfList['food_category.csv']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_We drop useless columns_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop unnecessary columns and rename to be more understandable\n",
    "food_nutrients_df = food_nutrients_df.drop([\"data_points\",\"min\",\"max\",\"median\",\"footnote\",\"min_year_acquired\",\"derivation_id\"],axis=1)\n",
    "\n",
    "nutrient_df = nutrient_df.drop([\"nutrient_nbr\",\"rank\"],axis=1)\n",
    "\n",
    "food_category_df.drop([\"code\"],axis=1,inplace=True)\n",
    "food_category_df.rename(columns={'id':'food_category_id','description':'category'},inplace= True)\n",
    "\n",
    "food_df.drop([\"publication_date\"],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>unit_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1003</td>\n",
       "      <td>Protein</td>\n",
       "      <td>G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1004</td>\n",
       "      <td>Total lipid (fat)</td>\n",
       "      <td>G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1008</td>\n",
       "      <td>Energy</td>\n",
       "      <td>KCAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1010</td>\n",
       "      <td>Sucrose</td>\n",
       "      <td>G</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id               name unit_name\n",
       "1  1003            Protein         G\n",
       "2  1004  Total lipid (fat)         G\n",
       "5  1008             Energy      KCAL\n",
       "7  1010            Sucrose         G"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#filter out only the necessary food nutrients since we have 227, a lot of which aren't necessary to determine if a food is healthy\n",
    "list_relevant_nutrients = [\"Protein\", \"Total Carbohydrate\",\"Total lipid (fat)\",\"Sucrose\",\\\n",
    "                            \"Glucose (dextrose)\",\"Sugars, total including NLEA\",\"Fatty acids, total monounsaturated\",\\\n",
    "                            \"Fatty acids, total polyunsaturated\",\"Fatty acids, total trans\",\"Fatty acids, total saturated\",\"Cholesterol\",\\\n",
    "                            \"Vitamin E, added\",\"Vitamin K (phylloquinone)\",\"Vitamin B-12\",\"Vitamin B-6\",\\\n",
    "                            \"Vitamin E (label entry primarily)\",\"Vitamin E (alpha-tocopherol)\",\"Vitamin D\",\"Vitamin A, RAE\",\"Sodium, Na\",\\\n",
    "                            \"Total fat (NLEA)\",\"Fiber, total dietary\",\"Energy\",\"Carbohydrate, by summation\",\"Fructose\"]\n",
    "\n",
    "nutrient_df = nutrient_df[nutrient_df.name.isin(list_relevant_nutrients)]\n",
    "nutrient_df.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'temp' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-102-8987c1101a4d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnutrient_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnutrient_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrim_nutrient_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   4040\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4041\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4042\u001b[0;31m                 \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4044\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-92-ad332e0a177c>\u001b[0m in \u001b[0;36mtrim_nutrient_name\u001b[0;34m(str1)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \"\"\"\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m#matches any separator and any whitespace and transforms to match to lower case\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtemp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"[;&@\\/:,\\*\\.\\(\\)\\{\\}\\\\%\\\"\\']\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstr1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m#remove duplicate word, as there are many\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'temp' referenced before assignment"
     ]
    }
   ],
   "source": [
    "nutrient_df.name = nutrient_df.name.apply(trim_nutrient_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nutrient_df.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_nutrients_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Add the names of the nutrients to the nutrients per food_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_nutrients_df = food_nutrients_df.join(nutrient_df.set_index('id'),on='nutrient_id',how='inner')\n",
    "\n",
    "#index the resulting table by multiindex: product id -> name of nutrients\n",
    "food_nutrients_df = food_nutrients_df.set_index(pd.MultiIndex.from_frame(food_nutrients_df[['fdc_id','name']]))\n",
    "#drop unnecessary columns \n",
    "food_nutrients_df = food_nutrients_df.drop([\"id\",\"fdc_id\",\"nutrient_id\",\"name\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#here is the result\n",
    "food_nutrients_df.loc[346049]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an example, we show the food contents of corned beef, the format matches our needs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_We add the food category to food_df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fdc_id</th>\n",
       "      <th>data_type</th>\n",
       "      <th>description</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>346049</td>\n",
       "      <td>branded_food</td>\n",
       "      <td>LIBBYS Corned Beef With Onion, 12 OZ</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>346050</td>\n",
       "      <td>branded_food</td>\n",
       "      <td>LIBBYS Corned Beef With Chili, 12 OZ</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>346464</td>\n",
       "      <td>branded_food</td>\n",
       "      <td>WOLF Chili Without Beans</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>346466</td>\n",
       "      <td>branded_food</td>\n",
       "      <td>WOLF Turkey Chili No Beans, 15 OZ</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>346468</td>\n",
       "      <td>branded_food</td>\n",
       "      <td>WOLF BRAND Chili With Beans, 24 oz., 24 OZ</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fdc_id     data_type                                 description category\n",
       "0  346049  branded_food        LIBBYS Corned Beef With Onion, 12 OZ      NaN\n",
       "1  346050  branded_food        LIBBYS Corned Beef With Chili, 12 OZ      NaN\n",
       "2  346464  branded_food                    WOLF Chili Without Beans      NaN\n",
       "3  346466  branded_food           WOLF Turkey Chili No Beans, 15 OZ      NaN\n",
       "4  346468  branded_food  WOLF BRAND Chili With Beans, 24 oz., 24 OZ      NaN"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "food_df = food_df.join(food_category_df.set_index(\"food_category_id\"),on=\"food_category_id\",how=\"left\")\n",
    "food_df.drop([\"food_category_id\"],axis=1,inplace=True)\n",
    "food_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_information_df = food_nutrients_df.join(food_df.set_index(\"fdc_id\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that a lot of categories are unfortunately missing from the governement database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_At this stage we have 3 dataframes from our additional dataset for nutrition:_\n",
    "- food_df = fdc_id vs name of food item (string)\n",
    "- food_name_df = fdc_id vs parsed food title (list of string)\n",
    "- food_nutrients_df = fdc_id vs nutrients contained (multiindex)\n",
    "- all_information_df = fdc_id, nutrients, data type, description and food category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_names_to_parse_df = food_df.copy()\n",
    "food_names_to_parse_df.description = food_names_to_parse_df.description.apply(parse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_df.description = food_df.description.apply(normalize_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_We filter the words according to their importance: that is, a word is more important as it apears many times in both datasets: (Ex: 'orange' is more important than 'artificial'). The words occuring in only one dataset are of no importance. The rest of the algorithm follows the following pipeline:_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVG(filename='untitled2.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_allwords(serie):\n",
    "    \"\"\"\n",
    "    serie: serie containing lists of words\n",
    "    return a dataframe containing\n",
    "      - column name: name of the unique articles found in the lists of the serie\n",
    "      - column count: how many times they appear in the serie\n",
    "    \"\"\"\n",
    "    allwords = np.concatenate(serie.ravel())\n",
    "    allwords = pd.Series(allwords)\n",
    "    allwords = pd.DataFrame(allwords,columns= [\"name\"])\n",
    "    allwords.reset_index(inplace = True)\n",
    "    allwords.rename(columns = {'index':'number'},inplace = True)\n",
    "    allwords = allwords.groupby('name').count().sort_values(by = 'number',ascending = False)\n",
    "    return allwords.reset_index()\n",
    "\n",
    "#all words present in the nutrition dataset\n",
    "all_words_nutrition = get_allwords(food_names_to_parse_df.description)\n",
    "\n",
    "#all words present in the product dataset\n",
    "all_words_supermarket = get_allwords(products_df.ingredients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inner merge between the 2 sets of words:\n",
    "\n",
    "_we check which words occur in both dataframes: only these words will have importance in determining the type of food article we are dealing with. Of course, if no words are known from the nutrition dataset, the sample is not taken into account._\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_words = pd.merge(all_words_supermarket,all_words_nutrition,left_on = 'name',right_on = 'name',suffixes=('_supermarket', '_nutrition'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3141\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>number_supermarket</th>\n",
       "      <th>number_nutrition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>frozen</td>\n",
       "      <td>5755</td>\n",
       "      <td>2633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>snacks</td>\n",
       "      <td>3178</td>\n",
       "      <td>1913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>meat</td>\n",
       "      <td>3090</td>\n",
       "      <td>2771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>dry</td>\n",
       "      <td>2991</td>\n",
       "      <td>2533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>premium</td>\n",
       "      <td>2423</td>\n",
       "      <td>4906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>packs</td>\n",
       "      <td>705</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>pet</td>\n",
       "      <td>682</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>sald</td>\n",
       "      <td>655</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>cake</td>\n",
       "      <td>654</td>\n",
       "      <td>2836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>natural</td>\n",
       "      <td>654</td>\n",
       "      <td>4044</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       name  number_supermarket  number_nutrition\n",
       "0    frozen                5755              2633\n",
       "1    snacks                3178              1913\n",
       "2      meat                3090              2771\n",
       "3       dry                2991              2533\n",
       "4   premium                2423              4906\n",
       "..      ...                 ...               ...\n",
       "95    packs                 705                77\n",
       "96      pet                 682                21\n",
       "97     sald                 655                 1\n",
       "98     cake                 654              2836\n",
       "99  natural                 654              4044\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(common_words.size)\n",
    "common_words.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "#Manual check to see which words occur in which dataset\n",
    "print('chocolate' in all_words_nutrition.name.values)\n",
    "print('chocolate' in all_words_supermarket.name.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assemble them together (and pray your god)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matches(test,food_list):\n",
    "    \"\"\"\n",
    "    test = list of strings to test\n",
    "    food_list: pandas dataframe linking the food article/id to the lists of words of its name\n",
    "    return all the articles whose words contain all of the words of test\n",
    "    \"\"\"\n",
    "    res =[]\n",
    "    for row in food_list[\"description\"]:\n",
    "        if all(el in test for el in row):\n",
    "            res.append(row)\n",
    "    return res\n",
    "    \n",
    "def get_importance(word):\n",
    "    \"\"\"\n",
    "    word: string for which we want to know the importance\n",
    "    return importance of word\n",
    "    \"\"\"\n",
    "    raise NotImplemented\n",
    "    \n",
    "def find_food(test,food_list):\n",
    "    \"\"\"\n",
    "    implementation of the graphic above\n",
    "    test = list of strings to test\n",
    "    food_list: pandas dataframe linking the food article/id to the lists of words of its name\n",
    "    return the best article\n",
    "    \"\"\"\n",
    "    if len(k) == 0:\n",
    "        #give up the sample\n",
    "        return 0 #dummy\n",
    "    \n",
    "    matches = get_matches(test,food_list)\n",
    "    if len(matches) == 0:\n",
    "        importance = [get_importance(i) for i in test]\n",
    "        mino = np.min(importance)\n",
    "        test = [i for i in test if i != mino]\n",
    "        return find_food(test,food_list)\n",
    "    elif len(matches) == 1:\n",
    "        return matches[0]\n",
    "    else:\n",
    "        sizes = [len(i) for i in matches]\n",
    "        minsize = np.min(sizes)\n",
    "        minsizes = [i for i in matches if len(i) == minsize]\n",
    "        if len(minsizes) == 1:\n",
    "            return minsizes[0]\n",
    "        else:\n",
    "            importances = [np.sum([get_importance(j) for j in trial]) for trial in minsizes]\n",
    "            armin_imp = np.argmin(importances)\n",
    "            return importances[armin_imp]\n",
    "                \n",
    "\n",
    "def find_food_naive(test,food_list):\n",
    "    \"\"\"\n",
    "    food_list: pandas dataframe linking the food article/id id to the lists of words of its name\n",
    "    test: list of strings you want to have an id for\n",
    "    return the corresponding food indx\n",
    "    \"\"\"\n",
    "    #TODO: improve the non unique max\n",
    "    scores = [get_score(test,i) for i in food_list.description]\n",
    "    maxo = np.max(scores)\n",
    "    if len([1 for x in scores if x == maxo]) > 1:\n",
    "        print(\"Multiple maximums!\")\n",
    "    armax = np.argmax(scores)\n",
    "    print('result: ',food_list.description[armax])\n",
    "    return food_list.fdc_id[armax]\n",
    "\n",
    "def get_score(test,trial):\n",
    "    \"\"\"\n",
    "    test: the list of strings you're trying to classify\n",
    "    trial: the list you want the score for\n",
    "    return the score of matching\n",
    "    \"\"\"\n",
    "    return np.sum([1 for i in test if i in trial])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TO DO\n",
    "get_matches(test1,food_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple maximums!\n",
      "result:  swiss miss creamy vanilla pudding 24 oz\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "346532"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test1 = ['vanilla','swiss','miss','pudding','24','oz']\n",
    "find_food_naive(test1,food_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO DO: put name and food category into gov database??"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
